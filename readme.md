# Projet d'Analyse de Sentiments
### Description du projet
Les conversations en ligne sont souvent marquées par la violence et la difficulté d'exprimer des idées de manière respectueuse, entraînant le risque d'abus et de harcèlement numérique qui incite à la réticence et au silence. Ce phénomène affaiblit le débat public, de plus en plus déplacé vers les plateformes numériques, qui réagissent en restreignant voire supprimant les commentaires des utilisateurs pour maintenir des échanges respectueux. Cependant, cette approche peut être perçue comme une forme de censure, compromettant le droit fondamental à la liberté d'expression, et souligne le besoin de trouver un équilibre entre la protection des utilisateurs et le respect de leur liberté d'expression. Dans ce contexte, Kaggle a lancé un concours avec l'équipe Conversation AI pour développer un modèle de machine learning détectant la toxicité en ligne, visant à rendre les interactions en ligne plus productives et respectueuses. Mon projet s'inscrit dans cette démarche en utilisant des données de commentaires Wikipedia, impliquant une analyse de sentiment basée sur le NLP pour créer un modèle favorisant une modération plus précise des contenus en ligne, avec une étape d'état de l'art, une analyse exploratoire des données, une modélisation, et enfin, le déploiement web du modèle final.

### Plan du travail
 - Etat de l’art dans le domaine de l’analyse de sentiment
 - Collete des données sur le site Kaggle
 - Analyse exploratoire des données
 - Prétraitement des données et vectorisation du texte
 - Modélisation et entraînement des modèles
 - Choix du modèle de classification et optimisation des performances
 - Analyse des résultats
 - Utilisation de l'apprentissage profond
 - Déploiement du Modèle avec Gradio

 ### Conclusion 

 Ce projet de détection de la toxicité dans les commentaires en ligne a été très enrichissant. J'ai exploré différentes techniques de prétraitement, de vectorisation et de modélisation pour développer un modèle de régression logistique capable d'identifier et de classifier les commentaires toxiques. Au cours de ce projet, j'ai réalisé une analyse exploratoire approfondie des données, identifié les défis liés à la modération des commentaires en ligne et examiné les différentes approches pour résoudre ce problème complexe. J'ai constaté que la modération automatisée des commentaires peut contribuer à créer un environnement en ligne plus sûr et respectueux, mais qu'elle doit être utilisée en complément de politiques de modération claires et d'une intervention humaine lorsque cela est nécessaire. Mon modèle de régression logistique de base a montré de bonnes performances globales, avec des scores élevés en termes de précision, de rappel, de F1 et d'AUC. Cependant, j'ai également identifié des limitations dans la détection précise des commentaires toxiques, en particulier pour certaines catégories spécifiques. Pour aller plus loin, des techniques avancées telles que l'utilisation d'incorporations de mots pré-entraînées et de modèles de réseaux neuronaux pourraient être explorées afin d'améliorer davantage les performances de détection. Ce projet a été une formidable opportunité pour moi d'approfondir ma compréhension des différentes facettes de la modération des commentaires en ligne à travers le prisme du traitement automatique du langage naturel (NLP). J'ai exploré et appliqué des concepts clés de la NLP tels que la vectorisation des mots, l'extraction de caractéristiques, la tokenisation, le prétraitement des données textuelles et l'application de divers modèles d'apprentissage automatique. L'apprentissage et l'application de la NLP dans ce contexte m'ont montré qu'elle peut être un outil puissant pour aider à rendre l'Internet un espace plus sûr et plus inclusif.
  ### Outils
  Python , PySpark, Git Lab, MlFlow, Gradio

  ### Compétences 
  - Traitement Automatique du Langage Naturel (NLP) : Tokenisation, Vectorisation des mots, et Extraction de caractéristiques 

  - Analyse Exploratoire des Données (EDA) 

  - Modélisation de Machine Learning 

  - Évaluation des Performances de Modèle  en utilisant des métriques telles que la précision, le rappel, la F1, et l'AUC pour mesurer l'efficacité de la détection de la toxicité.

 - Communication des Résultats : La capacité à communiquer de manière claire et concise les résultats du projet, y compris les performances du modèle, les limitations identifiées, et les recommandations pour des améliorations futures

 - Deploiement d'un modèle avec Gradio

